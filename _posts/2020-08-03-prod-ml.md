---
toc: true
layout: post
description: ProdML SageMaker note series
categories: [note, sagemaker, prodml, mlops]
title: "[Production Machine Learning] Amazon SageMaker Part I"
comments: true
---

## Overview

1. **Intro to Amazon SageMaker**: what it is, what it sovles
2. **Setting up a SageMaker Studio development environment**: create an instance of SageMaker Studio, and learn about its GUI, create Jupyter notebooks, and connect to git repos.
3. **Interactive model tranining in SageMaker Studio**: train model using builtin models and custom scripts, build Docker images for custom solution. Interact with SageMaker API using its Python SDK.
4. **Experiment management using Experiments**: train both TensorFlow and PyTorch to train CV models, and run experiments to find the best model
5. **Deploy trained models**: run batch offline inference, and deploy as API for production online inference. We will also show how to scale the production resource based on demand.
6. **Monitoring deployed models**: use SageMaker Model Monitor to monitor the model deployed in 5, inspect incoming data with training data to find if there is data drift

### Challenges of running production ML systems

- **Experimentation tracking**: selecting the best model from many iterations is hard
- **Debugging**: debugging in ML is hard, debugging an automated ML job is harder
- **Deployment**: deployment is not well understood since most data scientists lack DevOps and software engineering skills
- **Scaling**: instances need to automatically scale based on demand
- **Model monitoring**: models need to be monitored to identify regressions in quality, and provide signal for actions such as **model retraining, auditing upstream, fix data quality issues**.

We will solve these challenges with Amazon SageMaker! We will be able to

- train models using built-in algorithms and custom scripts
- run large scale experiments in an autoscaling distributed environment
- collect and analyze data from experiments
- perform offline inference on batch data
- deploy models as persistent endpoints that scale with demand
- monitor deployed endpoints for data drift

## 1. Intro to Amazon SageMaker

SageMaker is an ML platform. That means it lets you quickly train and deploy ML models to production.

It takes care of a lot of "plumbing" tasks for ML systems. These tasks are NOT feature engineering and algorithmic work. They are more mundane ones such as managing infra, logging, monitoring inputs and outputs. They enable us to do algorithmic work much easier.

SageMaker features:

- **Studio** - integrated ML environment where you can build, train, deploy, and analyze your models in one place.
- **Studio notebooks** - Jupyter notebook interface with Single Sign-On integration, fast startup time, and single click sharing
- **Preprocessing** - preprocess and analyze data over a distributed cluster
- **Experimenst** - experiment management and tracking
- **Debugger** - inspect data and error in automated training processes
- **Batch transform** - perform batch inference
- **Hosted endpoints** - deploy models as APIs
- **Model monitor** - monitor model quality

### 1.1 SageMaker architecture overview

SageMaker consists of several services.

- Docker: depending on your use case. To use builtin models, no need to work with Docker. If you have customized model and solutions, you need to build and publish Docker images.
- Elastic Container Registry (ECR): this is an AWS service. SageMaker gets the desired Docker image from ECR to run the job. Amazon has predefined Docker images for SageMaker to do basic things. We will use them later.
- S3: SageMaker stores and gets the data in S3.
- EC2: SageMaker launches EC2 instances to do the work and terminate when the job is complete. You only pay for the use. If you choose to deploy as an API, SageMaker launches the number of instances as you specify and does not terminate them. You can let it scale as needed.

<img src="{{ site.baseurl }}/images/prodml/sagemaker-arch.png" alt="SageMaker architecture" align="middle"/>

And there are 2 background services that are not directly relevant in the architecture but also important:

- CloudWatch: it monitors the resources and stores log files
- IAM: Amazon uses Identity and Access Management users to manage your access.

## 2. SageMaker Studio

Features

- Notebooks
- Experiments
- Autopilot (enable developers with no ML expertise to train models)
- Debugger
- Model Monitor

### 2.1 Create a Studio instance

In quick start, set your username,

<img src="{{ site.baseurl }}/images/prodml/sagemaker-create1.png" alt="Studio create 1" align="middle"/>

then create a new IAM role, leave the S3 setting to default unless you have special naming requirements.

<img src="{{ site.baseurl }}/images/prodml/sagemaker-create2.png" alt="Studio create 2" align="middle"/>

After creating the new IAM role, hit submit to create the SageMaker Studio instance. You'll see the following page and it will take a couple of minutes.

<img src="{{ site.baseurl }}/images/prodml/sagemaker-create3.png" alt="Studio create 3" align="middle"/>

### 2.2 Create a notebook

Once the Studio instance is created, click on file -> new -> notebook, select a kernel to start a new notebook. After that, the bottom left has a green message that should say "kernel starting", and at the top right there is "unknown" meaning the EC2 resource underlying the kernel is not ready yet. During the starting phase, you can't run any notebook code. Just wait for a while. Once it's ready, the "unknown" should turn to something like "2 vCPU + 4 GB".

The kernel tab on the left sidebar shows the active kernels (Docker images) you are running.

<img src="{{ site.baseurl }}/images/prodml/sagemaker-nb-kernel.png" alt="Kernel" align="middle"/>

The "Python3 (Data Science)" kernel has the usual data science libraries pre-installed.

<img src="{{ site.baseurl }}/images/prodml/ds-kernel.png" alt="Kernel DS" align="middle"/>

**IMPORTANT: Don't forget to stop the kernel when you are done! You get billed by the hour for active kernels based on the EC2 instance type.** Find the pricing details [here](https://aws.amazon.com/sagemaker/pricing/).

### Connect to a git repo in Studio

Click file -> new -> terminal, it opens a bash terminal for us. `git clone` your desired repo from Github.

Now you should see your repo's directory in the file browser in the left sidebar. You can also check the git history and status in the git tab in the sidebar.

### Install libraries

To install additional libraries to the kernel, just do it in the notebook like this

```
!{sys.executable} -m pip install sagemaker-experiments
!{sys.executable} -m pip install torch
!{sys.executable} -m pip install torchvision
```

### Demo in Notebook: Create S3 bucket

Running the following code in the notebook:

```py
BUCKET = 'sagemaker-course-20200804'

boto_session = boto3.Session()

try:
    if boto_session.region_name == "us-east-1":
        boto_session.client('s3').create_bucket(Bucket=BUCKET)
    else:
        boto_session.client('s3').create_bucket(
            Bucket=BUCKET,
            CreateBucketConfiguration={'LocationConstraint': boto_session.region_name})
except Exception as e:
    print(e)
```

It should run without any error. I went to the S3 console and verified, it worked.

## 3. Training models in SageMaker

We can either

- use builtin models, or
- write custom code and use a predefined Docker image to run it, or
- build our own Docker image and our own code to train customized solution (requires Docker knowledge)

Both the builtin model approach and the custom code approach will be demonstrated. Refer to the code in notebook [here](https://github.com/lpatruno/sagemaker-course/blob/master/notebooks/ch03_interactive_model_training.ipynb).

### 3.1 Train an XGBoost model with builtin algorithms

We can use the builtin XGBoost algorithm to train our model. To train the model, we need to first **upload the training data to S3**. We can use the SageMaker Python SDK to create a SageMaker Session object and a boto session object for S3 upload.

After uploading the data, we need to **create pointers to the data** in order to feed into the train function later.

Next, to train the model, we need to create a **training job**. It needs some info: the url of the S3 bucket (pointer), compute resource for training, url of s3 bucket to store the output, the Docker image for the predefined algorithm, etc.

<img src="{{ site.baseurl }}/images/prodml/sagemaker-xgboost.png" alt="sagemaker xgboost" align="middle"/>

tbd

### 3.2 Train an sklearn model using prebuilt Docker images and custom code

tbd


## Reference

- Luigi's SageMaker course

