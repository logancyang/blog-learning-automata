---
toc: true
layout: post
description: ProdML SageMaker note series
categories: [note, sagemaker, prodml, mlops]
title: "[ProdML] Amazon SageMaker Part II: Experiments, Deployment, and Monitoring"
comments: true
---

Previous post: [part I](https://blog.logancyang.com/note/sagemaker/prodml/mlops/2020/08/03/prod-ml.html)

## 4. Experiments

In the previous section we went through the training process. In reality, the model needs a series of experiments to find the best set of hyperparameters. It is very important to properly keep track of the experiment results in a reproducible manner, and setup unified practice among team members. SageMaker Experiments solves this problem.

SageMaker Experiments has its own Python package you can import with:

```py
from smexperiments.experiment import Experiment
```

An `experiment` should be the outer most group for a collections of `trial`s. Each trial can map to a specific algorithm you use, such as a Random Forest, XGBoost, Logistic Regression, etc.

```py
from smexperiments.trial import Trial
```

A trial is a series of steps, each step is called a `trial_component`.

```py
from smexperiments.trial_component import TrialComponent
```

Each trial component can have a combination of inputs such as datasets, algorithm and parameters. You can produce desired outputs such as models, datasets, metrics and checkpoints.

Examples of trial components are

- data preprocessing jobs
- training jobs
- batch transform jobs

A trial component can be, e.g. the full preprocessing logic, or each step within it such as imputing missing values, one-hot encoding, etc. Each trial component (a trial step) can store information such as mean and standard deviation or the metric you care about during the experiments so you can compare them.

Next let's look at examples for training MNIST classifiers using TensorFlow and PyTorch.

### 4.1 An Experiment Example using TensorFlow 2

We use a custom training script provided by TensorFlow for this use case. Check out the script [here](https://github.com/lpatruno/sagemaker-course/blob/master/scripts/tf/tensorflow_mnist.py).

Note that in `_parse_args()`, `model_dir` is passed from SageMaker and the others are from SageMaker environment variables.

```py
def _parse_args():
    parser = argparse.ArgumentParser()

    # Data, model, and output directories
    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.
    parser.add_argument('--model_dir', type=str)
    parser.add_argument('--sm-model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))
    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAINING'))
    parser.add_argument('--hosts', type=list, default=json.loads(os.environ.get('SM_HOSTS')))
    parser.add_argument('--current-host', type=str, default=os.environ.get('SM_CURRENT_HOST'))

    return parser.parse_known_args()
```

Here is the main block which is very simple:

```py
if __name__ == "__main__":
    args, unknown = _parse_args()

    train_data, train_labels = _load_training_data(args.train)
    eval_data, eval_labels = _load_testing_data(args.train)

    mnist_classifier = model(train_data, train_labels, eval_data, eval_labels)

    if args.current_host == args.hosts[0]:
        # save model to an S3 directory with version number '00000001'
        mnist_classifier.save(os.path.join(args.sm_model_dir, '000000001'), 'my_model.h5')
```

Note: the sample data from S3 is in `.npy` format which is much more performant than csv format.



### 4.2 An Experiment Example using PyTorch



## Reference

- Luigi's SageMaker course